{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "from PIL import Image\n",
    "import networkx as nx\n",
    "import h5py\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import dates\n",
    "from sklearn.cluster import (KMeans, SpectralClustering, AgglomerativeClustering, DBSCAN, OPTICS, Birch, MeanShift,\n",
    "AffinityPropagation)\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import mean_squared_error as mse, silhouette_score, pairwise_distances\n",
    "from glob import glob\n",
    "from peakfinder import detect_peaks\n",
    "from math import floor, ceil\n",
    "from itertools import combinations\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from loader import *\n",
    "from features import *\n",
    "from visualisation import *\n",
    "np.set_printoptions(suppress=False)\n",
    "scaler = standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav, soundings, shift_std, shift_mean, space, time = load_soundings(\"../data/level_1p0a/*[I|E].h5\", smoothing=\"poly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centred_soundings = centre(soundings)\n",
    "comp_wav, comp_centred_soundings = dropout(wav, centred_soundings, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad, polyres, poly_coeffs, curv = create_features(wav, centred_soundings, scaler, \"grad\", \"polyres\", \"poly_coeffs\", \"curv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logpolyres = np.log(polyres)/np.log(polyres).std(axis=0)\n",
    "cbrt_poly_coeffs = np.cbrt(poly_coeffs)\n",
    "cbrt_grad = np.cbrt(grad)\n",
    "cbrt_curv = np.cbrt(curv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.hstack([poly_coeffs[:,0:1], polyres[:,1:2], grad[:,4:5], curv[:,1:2]])\n",
    "sep_features = np.hstack([cbrt_poly_coeffs[:,0:1], logpolyres[:,1:2], cbrt_grad[:,4:5], cbrt_curv[:,1:2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features = np.hstack([scaler(centred_soundings), features])\n",
    "comp_combined_features = np.hstack([scaler(comp_centred_soundings), features])\n",
    "sep_combined_features = np.hstack([scaler(centred_soundings), sep_features])\n",
    "comp_sep_combined_features = np.hstack([scaler(comp_centred_soundings), sep_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"index = {\"poly_coeffs3\": poly_coeffs[:,0], \"poly_coeffs2\": poly_coeffs[:,1], \"poly_coeffs1\": poly_coeffs[:,2], \n",
    "         \"polyres1\": polyres[:,0], \"polyres2\": polyres[:,1], \"grad1\": grad[:,0], \"grad2\": grad[:,1], \n",
    "         \"grad3\": grad[:,2], \"grad4\": grad[:,3], \"curv1\": curv[:,0], \"curv2\": curv[:,1], \n",
    "         \"logpolyres1\": logpolyres[:,0], \"logpolyres2\": logpolyres[:,1], \"cbrt_poly_coeffs3\": cbrt_poly_coeffs[:,0], \n",
    "         \"cbrt_poly_coeffs2\": cbrt_poly_coeffs[:,1], \"cbrt_poly_coeffs1\": cbrt_poly_coeffs[:,2], \n",
    "         \"cbrt_grad1\": cbrt_grad[:,0], \"cbrt_grad2\": cbrt_grad[:,1], \"cbrt_grad3\": cbrt_grad[:,2], \n",
    "         \"cbrt_grad4\": cbrt_grad[:,3], \"cbrt_curv1\": cbrt_curv[:,0], \"cbrt_curv2\": cbrt_curv[:,1]}\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive and negative coefficient of $x^3$ is good at separating negative and positive curvature respectively, with periodic soundings with high magnitude coefficients at both ends.\n",
    "\n",
    "Coefficient of $x^2$ does the same in reverse order. Coefficient of $x$ does same as $x^3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Clustering\n",
    "Classifies periodic soundings if engineered features are used, puts periodic soundings in one cluster if raw transmissions are used.\n",
    "\n",
    "use knn graph because $\\epsilon$-neighbourhood works similarly to DBSCAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SpectralClustering(n_clusters=8, gamma=0.1).fit(comp_centred_soundings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clus = view_grouped_soundings(sc.labels_, wav, centred_soundings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agglomerative Clustering\n",
    "Computes a tree by iteratively joining together closest points and then number of clusters is specified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kng = kneighbors_graph(comp_combined_features, 5, mode='connectivity', include_self=True).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = AgglomerativeClustering(\n",
    "    n_clusters=20, memory=\"cache\", compute_full_tree=True, affinity=\"precomputed\", linkage=\"average\", connectivity=kng\n",
    "                            ).fit(comp_combined_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clus = view_grouped_soundings(ac.labels_, wav, centred_soundings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixtures \n",
    "Superset of k-means: gaussians instead of centroids. Number of components is analogous to number of clusters. \n",
    "\n",
    "weights means and covariances are initialsied using the result of a kmeans algorithm. Means are initialised as centroids, weights are the proportion of dataset assigned to each cluster, and covariances are the within-cluster covariances.\n",
    "\n",
    "Regularisation adds a small positive constant to the diagonal of the covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.arange(4) + 1e-15\n",
    "weights /= weights.sum()\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aic = []\n",
    "bic = []\n",
    "score = []\n",
    "\n",
    "for n in range(5,30):\n",
    "    gm = GaussianMixture(\n",
    "        n_components=n, covariance_type=\"full\", init_params=\"random\", verbose=False\n",
    "                            ).fit(standardised_combined_features)\n",
    "    score.append(gm.score(standardised_combined_features))\n",
    "    aic.append(gm.aic(standardised_combined_features))\n",
    "    bic.append(gm.bic(standardised_combined_features))\n",
    "\n",
    "\n",
    "plt.plot(np.arange(5,30), aic)\n",
    "plt.title(\"aic\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.plot(np.arange(5,30), bic)\n",
    "plt.title(\"bic\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.plot(np.arange(5,30), score)\n",
    "plt.title(\"log likelihood\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aic = []\n",
    "bic = []\n",
    "score = []\n",
    "\n",
    "for n in np.logspace(-7,-10,5):\n",
    "    gm = GaussianMixture(\n",
    "        n_components=15, covariance_type=\"full\", init_params=\"random\", verbose=False, tol=n, max_iter=int(1e15)\n",
    "                            ).fit(standardised_combined_features)\n",
    "    score.append(gm.score(standardised_combined_features))\n",
    "    aic.append(gm.aic(standardised_combined_features))\n",
    "    bic.append(gm.bic(standardised_combined_features))\n",
    "\n",
    "plt.semilogx(np.logspace(-7,-10,5), aic)\n",
    "plt.title(\"aic\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.semilogx(np.logspace(-7,-10,5), bic)\n",
    "plt.title(\"bic\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.semilogx(np.logspace(-7,-10,5), score)\n",
    "plt.title(\"log likelihood\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aic = []\n",
    "bic = []\n",
    "score = []\n",
    "\n",
    "for n in np.logspace(-9,-12,4):\n",
    "    gm = GaussianMixture(\n",
    "        n_components=15, covariance_type=\"full\", init_params=\"random\", verbose=False, tol=1e-7, max_iter=int(1e15),\n",
    "        reg_covar=n).fit(standardised_combined_features)\n",
    "    \n",
    "    score.append(gm.score(standardised_combined_features))\n",
    "    aic.append(gm.aic(standardised_combined_features))\n",
    "    bic.append(gm.bic(standardised_combined_features))\n",
    "\n",
    "plt.semilogx(np.logspace(-9,-12,4), aic)\n",
    "plt.title(\"aic\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.semilogx(np.logspace(-9,-12,4), bic)\n",
    "plt.title(\"bic\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.semilogx(np.logspace(-9,-12,4), score)\n",
    "plt.title(\"log likelihood\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gm = GaussianMixture(\n",
    "        n_components=15, covariance_type=\"full\", init_params=\"random\", tol=1e-15, max_iter=int(1e15), reg_covar=1e-15, \n",
    "                    ).fit(norm_combined_features)\n",
    "\n",
    "gmlabels = gm.predict(norm_combined_features)\n",
    "print(gm.score(norm_combined_features))\n",
    "clus = view_grouped_soundings(gmlabels, wav, centred_soundings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_feature_space(eng_features, [\"poly_coeffs\", \"polyres\", \"grad\"], br.labels_, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for cov in [\"full\", \"tied\", \"diag\", \"spherical\"]: \n",
    "    print(f\"\\n#### covariance type: {cov} ####\\n\")\n",
    "\n",
    "    gm = GaussianMixture(\n",
    "        n_components=15, covariance_type=\"full\", init_params=\"random\", tol=1e-3, max_iter=100, reg_covar=1e-14, verbose=True\n",
    "                            ).fit_predict(att_standardised_combined_features)\n",
    "\n",
    "    clus = view_clusters(gm, wav, centred_soundings, [\"cbrt_poly_coeffs3\", index[\"cbrt_poly_coeffs3\"]], \n",
    "                         [\"cbrt_grad300_350\", index[\"cbrt_grad300_350\"]], [\"logpolyres1\", index[\"logpolyres1\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for cov in [\"full\", \"tied\", \"diag\", \"spherical\"]: \n",
    "    print(f\"\\n#### covariance type: {cov} ####\\n\")\n",
    "    gm = GaussianMixture(\n",
    "        n_components=15, covariance_type=cov, init_params=\"random\", n_init=3, tol=1e-5, max_iter=1000, reg_covar=0, verbose=True\n",
    "                            ).fit_predict(att_eng_features)\n",
    "\n",
    "    clus = view_clusters(gm, wav, centred_soundings, [\"cbrt_poly_coeffs3\", index[\"cbrt_poly_coeffs3\"]], \n",
    "                         [\"cbrt_grad300_350\", index[\"cbrt_grad300_350\"]], [\"logpolyres1\", index[\"logpolyres1\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for cov in [\"full\", \"tied\", \"diag\", \"spherical\"]: \n",
    "    print(f\"\\n#### covariance type: {cov} ####\\n\")\n",
    "    gm = GaussianMixture(\n",
    "        n_components=15, covariance_type=cov, init_params=\"random\", n_init=3, tol=1e-5, max_iter=1000, reg_covar=0, verbose=True\n",
    "                            ).fit_predict(comp_centred_soundings)\n",
    "\n",
    "    clus = view_clusters(gm, wav, centred_soundings, [\"cbrt_poly_coeffs3\", index[\"cbrt_poly_coeffs3\"]], \n",
    "                         [\"cbrt_grad300_350\", index[\"cbrt_grad300_350\"]], [\"logpolyres1\", index[\"logpolyres1\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for cov in [\"full\", \"tied\", \"diag\", \"spherical\"]: \n",
    "    print(f\"\\n#### covariance type: {cov} ####\\n\")\n",
    "    gm = GaussianMixture(\n",
    "        n_components=15, covariance_type=cov, init_params=\"random\", n_init=3, tol=1e-5, max_iter=1000, reg_covar=1e-14, verbose=True\n",
    "                            ).fit_predict(standardised_combined_features)\n",
    "\n",
    "    clus = view_clusters(gm, wav, centred_soundings, [\"poly_coeffs3\", index[\"poly_coeffs3\"]], \n",
    "                         [\"grad300_350\", index[\"grad300_350\"]], [\"logpolyres1\", index[\"polyres1\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for cov in [\"full\", \"tied\", \"diag\", \"spherical\"]: \n",
    "    print(f\"\\n#### covariance type: {cov} ####\\n\")\n",
    "    gm = GaussianMixture(\n",
    "        n_components=15, covariance_type=cov, init_params=\"random\", n_init=3, tol=1e-5, max_iter=1000, reg_covar=0, verbose=True\n",
    "                            ).fit_predict(eng_features)\n",
    "\n",
    "    clus = view_clusters(gm, wav, centred_soundings, [\"poly_coeffs3\", index[\"poly_coeffs3\"]], \n",
    "                         [\"grad300_350\", index[\"grad300_350\"]], [\"polyres0\", index[\"polyres0\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Shift\n",
    "High bandwidth puts all soundings in the same cluster. A well tuned bandwidth will automatically detect the appropriate number of clusters.\n",
    "\n",
    "Sliding windows will move towards areas of high density and the bandwidth controls the colume of the sliding windows so they can cluster the entire dataset into one cluster, create clusters for individual points, or if fine tuned find local density maxima in the feature space.\n",
    "\n",
    "bandwith ~ 0.04 for raw spectra \n",
    "\n",
    "engineered features: bandwidth ~ 2, classifies periodic soundings well\n",
    "\n",
    "good with non-periodic soundings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = []\n",
    "for n in np.linspace(0.1, 1, 10):\n",
    "    ms = MeanShift(bandwidth=n, cluster_all=True).fit(standardised_combined_features)\n",
    "    n_clusters.append(len(set(ms.labels_)))\n",
    "    \n",
    "plt.plot(np.linspace(0.1,1,10), n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = MeanShift(bandwidth=0.03, cluster_all=True, n_jobs=-1).fit(comp_centred_soundings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(ms.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clus = view_grouped_soundings(ms.labels_, wav, centred_soundings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_feature_space(eng_features, [\"poly_coeffs\", \"polyres\", \"grad\"], br.labels_, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIRCH\n",
    "Creates a cluster feature tree, branching factor controls how many children can be added to a node in the tree and threshold controls the size of subclusters.\n",
    "\n",
    "###### optimal parameters for feature spaces\n",
    "standardised combined_features: threshold = 4.925, branching_factor=5\n",
    "\n",
    "norm_combined_features: threshold=0.9, branching_factor=50. (Usually decreasing threshold results in more clusters but decreasing from 0.9 to 0.89 decreases number of clusters by 1.)\n",
    "\n",
    "separating with logarithm and cube root produces lower quality clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br = Birch(n_clusters=None, threshold=4, branching_factor=50).fit(combined_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(set(br.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clus = view_grouped_soundings(br.labels_, wav, centred_soundings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_feature_space(features, names, labels, c=None):\n",
    "    \"\"\"\n",
    "    View feature space with specified cluster highlighted in yellow\n",
    "    \"\"\"\n",
    "    n_features = features.shape[1]\n",
    "    \n",
    "    if n_features == 2:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot()\n",
    "        \n",
    "        if c == None:\n",
    "            ax.scatter(features[:,0], features[:,1], c=labels.astype(float))\n",
    "        else:\n",
    "            ax.scatter(features[:,0], features[:,1], c=(labels==c).astype(float))\n",
    "            \n",
    "        ax.set_xlabel(names[0])\n",
    "        ax.set_ylabel(names[1])\n",
    "\n",
    "    elif n_features == 3:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(projection=\"3d\")\n",
    "        \n",
    "        if c == None:\n",
    "            ax.scatter(features[:,0], features[:,1], features[:,2], c=labels.astype(float))\n",
    "        else:\n",
    "            ax.scatter(features[:,0], features[:,1], features[:,2], c=(labels==c).astype(float))\n",
    "            \n",
    "        ax.set_xlabel(names[0])\n",
    "        ax.set_ylabel(names[1])\n",
    "        ax.set_zlabel(names[2])\n",
    "        \n",
    "    else:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot()\n",
    "        \n",
    "        if c == None:\n",
    "            ax.scatter(features[:,0], features[:,1], c=labels.astype(float))\n",
    "        else:\n",
    "            ax.scatter(features[:,0], features[:,1], c=(labels==c).astype(float))\n",
    "            \n",
    "        ax.set_xlabel(names[0])\n",
    "        ax.set_ylabel(names[1])\n",
    "        view_feature_space(features[:,2:], names[2:], labels, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_feature_space(features, [\"poly_coeffs\", \"polyres\", \"gradient\", \"curvature\"], br.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
