{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ermongroup.github.io/blog/a-tutorial-on-mmd-variational-autoencoders/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://github.com/ShengjiaZhao/MMD-Variational-Autoencoder/blob/master/mmd_vae.ipynb\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math, os\n",
    "from itertools import combinations\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soundings = np.genfromtxt(\"../data/soundings.csv\", delimiter=\",\")\n",
    "soundings = soundings[:-150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soundings = soundings.reshape(64, 200, 101)\n",
    "soundings = torch.tensor(soundings, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_features(features):\n",
    "    \"\"\"\n",
    "    Plots scatter plots of every 2 element combination of our features\n",
    "    \"\"\"\n",
    "    combs = list(combinations(range(features.shape[1]), 2))\n",
    "    n = len(combs)\n",
    "    rows = ceil(n/4)\n",
    "    fig = plt.figure(figsize=(20,4*rows))\n",
    "    axes = []\n",
    "    for i in range(n):\n",
    "        axes.append(fig.add_subplot(rows,4,i+1))\n",
    "        axes[i].scatter(features[:,combs[i][0]], features[:,combs[i][1]])\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "    \n",
    "class Reshape(torch.nn.Module):\n",
    "    def __init__(self, outer_shape):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.outer_shape = outer_shape\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), *self.outer_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flatten_output():\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(1, 64, 4, 2),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Conv2d(64, 128, 4, 2),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        Flatten(),\n",
    "    )\n",
    "    return model(Variable(torch.rand(2,1,28,28))).size()\n",
    "get_flatten_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reshape_output():\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(2, 1024),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(1024, 7*7*128),\n",
    "        torch.nn.ReLU(),\n",
    "        Reshape((128,7,7,)),\n",
    "        torch.nn.ConvTranspose2d(128, 64, 4, 2),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.ConvTranspose2d(64, 1, 4, 2, padding=3),\n",
    "        torch.nn.Sigmoid()\n",
    "    )\n",
    "    return model(Variable(torch.rand(2,2))).size()\n",
    "get_reshape_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder and decoder use the DC-GAN architecture\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.model = torch.nn.ModuleList([\n",
    "            #torch.nn.Conv2d(1, 64, 4, 2, padding=1),\n",
    "            #torch.nn.LeakyReLU(),\n",
    "            #torch.nn.Conv2d(64, 128, 4, 2, padding=1),\n",
    "            #torch.nn.LeakyReLU(),\n",
    "            #Flatten(),\n",
    "            torch.nn.Linear(101, 80),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(80, 50),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(50, z_dim)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(\"Encoder\")\n",
    "        #print(x.size())\n",
    "        for layer in self.model:\n",
    "            x = layer(x)\n",
    "            #print(x.size())\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.model = torch.nn.ModuleList([\n",
    "            torch.nn.Linear(z_dim, 50),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(50, 80),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(80, 101),\n",
    "            torch.nn.ReLU()\n",
    "            #Reshape((128,7,7,)),\n",
    "            #torch.nn.ConvTranspose2d(128, 64, 4, 2, padding=1),\n",
    "            #torch.nn.ReLU(),\n",
    "            #torch.nn.ConvTranspose2d(64, 1, 4, 2, padding=1),\n",
    "            #torch.nn.Sigmoid()\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(\"Decoder\")\n",
    "        #print(x.size())\n",
    "        for layer in self.model:\n",
    "            x = layer(x)\n",
    "            #print(x.size())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kernel(x, y):\n",
    "    x_size = x.size(0)\n",
    "    y_size = y.size(0)\n",
    "    dim = x.size(1)\n",
    "    x = x.unsqueeze(1) # (x_size, 1, dim)\n",
    "    y = y.unsqueeze(0) # (1, y_size, dim)\n",
    "    tiled_x = x.expand(x_size, y_size, dim)\n",
    "    tiled_y = y.expand(x_size, y_size, dim)\n",
    "    kernel_input = (tiled_x - tiled_y).pow(2).mean(2)/float(dim)\n",
    "    return torch.exp(-kernel_input) # (x_size, y_size)\n",
    "\n",
    "def compute_mmd(x, y):\n",
    "    x_kernel = compute_kernel(x, x)\n",
    "    y_kernel = compute_kernel(y, y)\n",
    "    xy_kernel = compute_kernel(x, y)\n",
    "    mmd = x_kernel.mean() + y_kernel.mean() - 2*xy_kernel.mean()\n",
    "    return mmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.encoder = Encoder(z_dim)\n",
    "        self.decoder = Decoder(z_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_reconstructed = self.decoder(z)\n",
    "        return z, x_reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z, x_reconstructed = model(Variable(torch.rand(1,1,28,28)))\n",
    "z.size(), x_reconstructed.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a numpy array of shape [batch_size, height, width, 1] into a displayable array \n",
    "# of shape [height*sqrt(batch_size, width*sqrt(batch_size))] by tiling the images\n",
    "def convert_to_display(samples):\n",
    "    cnt, height, width = int(math.floor(math.sqrt(samples.shape[0]))), samples.shape[1], samples.shape[2]\n",
    "    samples = np.transpose(samples, axes=[1, 0, 2, 3])\n",
    "    samples = np.reshape(samples, [height, cnt, cnt, width])\n",
    "    samples = np.transpose(samples, axes=[1, 0, 2, 3])\n",
    "    samples = np.reshape(samples, [height*cnt, width*cnt])\n",
    "    return samples\n",
    "\n",
    "\n",
    "def train(\n",
    "    dataloader,\n",
    "    z_dim=2,\n",
    "    n_epochs=10,\n",
    "    use_cuda=True,\n",
    "    print_every=100,\n",
    "    plot_every=500\n",
    "):\n",
    "    model = Model(z_dim)\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "    #print(model)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    i = -1\n",
    "    for epoch in range(n_epochs):\n",
    "        for images in soundings:\n",
    "            i += 1\n",
    "            optimizer.zero_grad()\n",
    "            x = Variable(images, requires_grad=False)\n",
    "            true_samples = Variable(\n",
    "                torch.randn(200, z_dim),\n",
    "                requires_grad=False\n",
    "            )\n",
    "            if use_cuda:\n",
    "                x = x.cuda()\n",
    "                true_samples = true_samples.cuda()\n",
    "            z, x_reconstructed = model(x)\n",
    "            mmd = compute_mmd(true_samples, z)\n",
    "            nll = (x_reconstructed - x).pow(2).mean()\n",
    "            loss = nll + mmd\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if i % print_every == 0:\n",
    "                print(\"Negative log likelihood is {:.5f}, mmd loss is {:.5f}\".format(\n",
    "                    nll.item(), mmd.item()))\n",
    "            if i % plot_every == 0:\n",
    "                gen_z = Variable(\n",
    "                    torch.randn(100, z_dim),\n",
    "                    requires_grad=False\n",
    "                )\n",
    "                if use_cuda:\n",
    "                    gen_z = gen_z.cuda()\n",
    "                samples = model.decoder(gen_z)\n",
    "                losses.append(loss)\n",
    "                continue\n",
    "                samples = samples.permute(0,2,3,1).contiguous().cpu().data.numpy()\n",
    "                plt.imshow(convert_to_display(samples), cmap='Greys_r')\n",
    "                plt.show()\n",
    "    plt.plot(x[0].cpu().detach())\n",
    "    plt.show()\n",
    "    plt.plot(x_reconstructed[0].cpu().detach())\n",
    "    plt.show()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=200\n",
    "mnist_train = torch.utils.data.DataLoader(\n",
    "    MNIST(\"./tmp/MNIST\", train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=3,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "z_dim = 20\n",
    "model = train(mnist_train, z_dim=z_dim, n_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scatter_features(model(Variable(soundings.reshape(-1,101).to(\"cuda:0\")))[0].cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If latent z is 2-dimensional we visualize it by plotting latent z of different digits in different colors\n",
    "if z_dim == 2:\n",
    "    test_batch_size = 500\n",
    "    mnist_test = torch.utils.data.DataLoader(\n",
    "        MNIST(\"./tmp/MNIST\", train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                       ])),\n",
    "        batch_size=test_batch_size, shuffle=True, num_workers=3,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    z_list, label_list = [], []\n",
    "    for i in range(20):\n",
    "        batch_x, batch_y = iter(mnist_test).next()\n",
    "        batch_x = Variable(batch_x, requires_grad=False).cuda()\n",
    "        z = model.encoder(batch_x)\n",
    "        z_list.append(z.cpu().data.numpy())\n",
    "        label_list.append(batch_y.numpy())\n",
    "    z = np.concatenate(z_list, axis=0)\n",
    "    label = np.concatenate(label_list)\n",
    "    plt.scatter(z[:, 0], z[:, 1], c=label)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "c99ec3b06bb2b7a9ce1cfef1038d6bd1f5e5eb8cf3fb3cc6612960f8106f6dac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
